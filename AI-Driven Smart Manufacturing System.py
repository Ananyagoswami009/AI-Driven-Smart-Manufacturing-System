# -*- coding: utf-8 -*-
"""Jeet's Notebook

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G8AVni9OubVDBn1qjXQHJFtpN8OeE2Pg
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d thefool484/topology-optimization-top88

!unzip topology-optimization-top88.zip -d topology_data

import os

# List all files in the directory
files = os.listdir("topology_data")
print(files)

# List all files in the 'To-Data-ver2' folder
sub_files = os.listdir("topology_data/To-Data-ver2")
print(sub_files)

# List files in the 'Midload' folder
midload_files = os.listdir("topology_data/To-Data-ver2/Midload")
print("Files in 'Midload':", midload_files)

# List files in the 'Endload' folder
endload_files = os.listdir("topology_data/To-Data-ver2/Endload")
print("Files in 'Endload':", endload_files)

# List files in the 'Combine' folder
combine_files = os.listdir("topology_data/To-Data-ver2/Combine")
print("Files in 'Combine':", combine_files)

import os

# Define the base directory
base_dir = "topology_data/To-Data-ver2"

# Define subdirectories
subdirs = ["Midload", "Endload", "Combine"]
subfolders = ["train", "val", "test"]

# Iterate through each subdirectory and subfolder
for subdir in subdirs:
    print(f"--- Files in '{subdir}' ---")
    for subfolder in subfolders:
        folder_path = os.path.join(base_dir, subdir, subfolder)
        if os.path.exists(folder_path):
            files = os.listdir(folder_path)
            print(f"Files in '{subfolder}':", files)
        else:
            print(f"Subfolder '{subfolder}' does not exist in '{subdir}'")
    print()

import os

# Check the files in the labels directory
for file in os.listdir(labels_dir):
    label_path = os.path.join(labels_dir, file)
    print(file, "is binary:", open(label_path, "rb").read(1) == b'\x89')  # Check binary signature

import os
from PIL import Image
import numpy as np

# Define the base paths
base_dir = "topology_data/To-Data-ver2"
scenario = "Midload"  # Choose 'Midload', 'Endload', or 'Combine'
subset = "train"  # Choose 'train', 'val', or 'test'

# Define directories for images and labels
images_dir = os.path.join(base_dir, scenario, subset, "images")
labels_dir = os.path.join(base_dir, scenario, subset, "labels")

# Load input images
input_images = []
image_files = sorted(os.listdir(images_dir))
for file in image_files:
    img_path = os.path.join(images_dir, file)
    img = Image.open(img_path).convert("L")  # Convert to grayscale
    img_resized = img.resize((128, 128))  # Resize to 128x128 (optional)
    input_images.append(np.array(img_resized))

# Load label images
label_images = []
label_files = sorted(os.listdir(labels_dir))
for file in label_files:
    label_path = os.path.join(labels_dir, file)
    label_img = Image.open(label_path).convert("L")  # Convert to grayscale
    label_resized = label_img.resize((128, 128))  # Resize to match input images
    label_images.append(np.array(label_resized))

# Convert to numpy arrays
input_images = np.array(input_images)
label_images = np.array(label_images)

# Print shapes for verification
print("Input Images Shape:", input_images.shape)
print("Label Images Shape:", label_images.shape)

import matplotlib.pyplot as plt

for i in range(5):
    plt.figure(figsize=(8, 4))
    plt.subplot(1, 2, 1)
    plt.imshow(input_images[i], cmap="gray")
    plt.title("Input Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(label_images[i], cmap="gray")
    plt.title("Label Image")
    plt.axis("off")

    plt.show()

import matplotlib.pyplot as plt

# Display a few input-label pairs
for i in range(5):  # Adjust the range if needed
    plt.figure(figsize=(8, 4))

    # Input image
    plt.subplot(1, 2, 1)
    plt.imshow(input_images[i], cmap="gray")
    plt.title("Input Image")
    plt.axis("off")

    # Corresponding label image
    plt.subplot(1, 2, 2)
    plt.imshow(label_images[i], cmap="gray")
    plt.title("Label Image")
    plt.axis("off")

    plt.show()

input_images = input_images / 255.0
label_images = label_images / 255.0

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    input_images, label_images, test_size=0.2, random_state=42
)

print("Training Set Shape:", X_train.shape, y_train.shape)
print("Validation Set Shape:", X_val.shape, y_val.shape)

pip install tensorflow

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Define U-Net Model
def unet_model(input_shape=(128, 128, 1)):
    inputs = Input(input_shape)

    # Encoder
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    # Bottleneck
    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)

    # Decoder
    u1 = UpSampling2D((2, 2))(c4)
    u1 = Concatenate()([u1, c3])
    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(u1)
    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)

    u2 = UpSampling2D((2, 2))(c5)
    u2 = Concatenate()([u2, c2])
    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u2)
    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(c6)

    u3 = UpSampling2D((2, 2))(c6)
    u3 = Concatenate()([u3, c1])
    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u3)
    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(c7)

    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)

    model = Model(inputs, outputs)
    return model

# Instantiate the model
input_shape = (128, 128, 1)  # Grayscale images
model = unet_model(input_shape)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])

# Display model summary
model.summary()

# Prepare data for training (add channel dimension to images for compatibility)
X_train = X_train[..., np.newaxis]  # Add channel dimension
X_val = X_val[..., np.newaxis]
y_train = y_train[..., np.newaxis]
y_val = y_val[..., np.newaxis]

# Train the model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=8,
    verbose=1
)

# Save the trained model
model.save('/mnt/data/unet_topology_model.h5')

import matplotlib.pyplot as plt

# Predict on validation data
predictions = model.predict(X_val)

# Visualize a few predictions
for i in range(5):  # Display first 5 samples
    plt.figure(figsize=(12, 4))

    # Input Image
    plt.subplot(1, 3, 1)
    plt.imshow(X_val[i].squeeze(), cmap='gray')
    plt.title("Input Image")
    plt.axis("off")

    # Ground Truth
    plt.subplot(1, 3, 2)
    plt.imshow(y_val[i].squeeze(), cmap='gray')
    plt.title("Ground Truth")
    plt.axis("off")

    # Predicted Image
    plt.subplot(1, 3, 3)
    plt.imshow(predictions[i].squeeze(), cmap='gray')
    plt.title("Predicted Image")
    plt.axis("off")

    plt.show()

from skimage.metrics import structural_similarity as ssim
import numpy as np

# Calculate SSIM for the validation set
ssim_scores = []
for i in range(len(X_val)):
    ssim_score = ssim(y_val[i].squeeze(), predictions[i].squeeze(), data_range=1.0)
    ssim_scores.append(ssim_score)

# Compute average SSIM
avg_ssim = np.mean(ssim_scores)
print("Average SSIM:", avg_ssim)

from tensorflow.keras.optimizers import Adam

# Compile the model with a reduced learning rate
model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])

# Fine-tune the model
history_fine_tune = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=8,
    verbose=1
)

import tensorflow as tf

# Define SSIM-based loss function
def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

# Define combined loss function: MSE + SSIM
def combined_loss(y_true, y_pred):
    mse_loss = tf.keras.losses.MeanSquaredError()(y_true, y_pred)
    ssim_loss_value = ssim_loss(y_true, y_pred)
    return mse_loss + ssim_loss_value

# Compile the model with the combined loss function
model.compile(optimizer=Adam(learning_rate=0.0001), loss=combined_loss, metrics=['mae'])

# Train the model again with the enhanced loss function
history_combined_loss = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=8,
    verbose=1
)

predictions = model.predict(X_val)

import matplotlib.pyplot as plt

for i in range(5):
    plt.figure(figsize=(12, 4))

    # Input Image
    plt.subplot(1, 3, 1)
    plt.imshow(X_val[i].squeeze(), cmap='gray')
    plt.title("Input Image")
    plt.axis("off")

    # Ground Truth
    plt.subplot(1, 3, 2)
    plt.imshow(y_val[i].squeeze(), cmap='gray')
    plt.title("Ground Truth")
    plt.axis("off")

    # Predicted Image
    plt.subplot(1, 3, 3)
    plt.imshow(predictions[i].squeeze(), cmap='gray')
    plt.title("Predicted Image")
    plt.axis("off")

    plt.show()

from skimage.metrics import structural_similarity as ssim
import numpy as np

ssim_scores = [ssim(y_val[i].squeeze(), predictions[i].squeeze(), data_range=1.0) for i in range(len(X_val))]
avg_ssim = np.mean(ssim_scores)
print("Average SSIM:", avg_ssim)

# Save the model in the recommended native Keras format
model.save('/mnt/data/final_unet_topology_model.keras')

model.save('/mnt/data/final_unet_topology_model.h5', save_format='h5')



"""visulazation of model 1
**bold text**
"""

import matplotlib.pyplot as plt

# Visualize more examples (adjust the range as needed)
for i in range(10):  # Display 10 examples
    plt.figure(figsize=(15, 5))

    # Input Image
    plt.subplot(1, 3, 1)
    plt.imshow(X_val[i].squeeze(), cmap='gray')
    plt.title("Input Image")
    plt.axis("off")

    # Ground Truth
    plt.subplot(1, 3, 2)
    plt.imshow(y_val[i].squeeze(), cmap='gray')
    plt.title("Ground Truth")
    plt.axis("off")

    # Predicted Image
    plt.subplot(1, 3, 3)
    plt.imshow(predictions[i].squeeze(), cmap='gray')
    plt.title("Predicted Image")
    plt.axis("off")

    plt.show()

for i in range(5):  # Display 5 examples
    plt.figure(figsize=(12, 4))

    # Input Image
    plt.subplot(1, 3, 1)
    plt.imshow(X_val[i].squeeze(), cmap='gray')
    plt.title("Input Image")
    plt.axis("off")

    # Error Map
    plt.subplot(1, 3, 2)
    error_map = np.abs(y_val[i].squeeze() - predictions[i].squeeze())
    plt.imshow(error_map, cmap='hot')
    plt.title("Error Map")
    plt.axis("off")

    # Ground Truth vs Prediction
    plt.subplot(1, 3, 3)
    plt.imshow(y_val[i].squeeze(), cmap='gray', alpha=0.5, label="Ground Truth")
    plt.imshow(predictions[i].squeeze(), cmap='jet', alpha=0.5, label="Prediction")
    plt.title("Overlay: Ground Truth & Prediction")
    plt.axis("off")

    plt.show()

from skimage.metrics import structural_similarity as ssim

# Calculate SSIM scores
ssim_scores = [ssim(y_val[i].squeeze(), predictions[i].squeeze(), data_range=1.0) for i in range(len(X_val))]

# Plot SSIM scores
plt.figure(figsize=(10, 5))
plt.bar(range(len(ssim_scores)), ssim_scores)
plt.xlabel("Sample Index")
plt.ylabel("SSIM Score")
plt.title("SSIM Scores for Validation Samples")
plt.ylim(0, 1)
plt.show()

# Training and Validation Loss
plt.figure(figsize=(8, 5))
plt.plot(history_combined_loss.history['loss'], label='Training Loss')
plt.plot(history_combined_loss.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training and Validation Loss")
plt.legend()
plt.show()

# Training and Validation MAE
plt.figure(figsize=(8, 5))
plt.plot(history_combined_loss.history['mae'], label='Training MAE')
plt.plot(history_combined_loss.history['val_mae'], label='Validation MAE')
plt.xlabel("Epochs")
plt.ylabel("MAE")
plt.title("Training and Validation MAE")
plt.legend()
plt.show()

def plot_pixel_histogram(input_img, predicted_img, ground_truth):
    plt.figure(figsize=(8, 5))

    plt.hist(input_img.ravel(), bins=50, alpha=0.5, label="Input Image", color='blue')
    plt.hist(predicted_img.ravel(), bins=50, alpha=0.5, label="Predicted Image", color='orange')
    plt.hist(ground_truth.ravel(), bins=50, alpha=0.5, label="Ground Truth", color='green')

    plt.xlabel("Pixel Intensity")
    plt.ylabel("Frequency")
    plt.title("Pixel Intensity Histogram")
    plt.legend()
    plt.show()

# Example for first sample
plot_pixel_histogram(X_val[0].squeeze(), predictions[0].squeeze(), y_val[0].squeeze())

def highlight_differences(ground_truth, predicted_image, threshold=0.1):
    difference = np.abs(ground_truth - predicted_image)
    highlighted = (difference > threshold).astype(np.float32)

    plt.figure(figsize=(12, 4))

    # Ground Truth
    plt.subplot(1, 3, 1)
    plt.imshow(ground_truth, cmap='gray')
    plt.title("Ground Truth")
    plt.axis("off")

    # Predicted Image
    plt.subplot(1, 3, 2)
    plt.imshow(predicted_image, cmap='gray')
    plt.title("Predicted Image")
    plt.axis("off")

    # Highlighted Differences
    plt.subplot(1, 3, 3)
    plt.imshow(highlighted, cmap='hot')
    plt.title("Highlighted Differences")
    plt.axis("off")

    plt.show()

# Example for first sample
highlight_differences(y_val[0].squeeze(), predictions[0].squeeze())

def plot_confidence_heatmap(predicted_image):
    plt.figure(figsize=(6, 6))
    plt.imshow(predicted_image, cmap='hot')
    plt.colorbar(label="Confidence")
    plt.title("Prediction Confidence Heatmap")
    plt.axis("off")
    plt.show()

# Example for first prediction
plot_confidence_heatmap(predictions[0].squeeze())

import matplotlib.pyplot as plt
import numpy as np


ssim_scores = [ssim(y_val[i].squeeze(), predictions[i].squeeze(), data_range=1.0) for i in range(len(X_val))]

# Generate x-axis values for the samples
x_values = range(len(ssim_scores))

# Create a smoother and visually appealing line chart for SSIM scores
plt.figure(figsize=(12, 6))
plt.plot(x_values, ssim_scores, marker='o', linestyle='-', color='blue', label='SSIM Score', linewidth=2)

# Add horizontal grid lines for clarity
plt.grid(axis='y', alpha=0.7)

# Add titles and labels
plt.title("SSIM Scores for Validation Samples", fontsize=16)
plt.xlabel("Sample Index", fontsize=14)
plt.ylabel("SSIM Score", fontsize=14)

# Customize ticks
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Add a legend
plt.legend(fontsize=12)

# Set limits for better visualization
plt.ylim(0, 1)

# Display the plot
plt.show()

# Box plot for SSIM scores
plt.figure(figsize=(8, 6))
plt.boxplot(ssim_scores, patch_artist=True, boxprops=dict(facecolor="lightblue"))
plt.title("SSIM Score Distribution", fontsize=16)
plt.ylabel("SSIM Score", fontsize=14)
plt.xticks([1], ["SSIM Scores"], fontsize=12)
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# Training and Validation Loss
plt.figure(figsize=(10, 6))
plt.plot(history_combined_loss.history['loss'], label='Training Loss', color='blue', linewidth=2)
plt.plot(history_combined_loss.history['val_loss'], label='Validation Loss', color='orange', linewidth=2)
plt.title("Training and Validation Loss Over Epochs", fontsize=16)
plt.xlabel("Epochs", fontsize=14)
plt.ylabel("Loss", fontsize=14)
plt.legend(fontsize=12)
plt.grid(alpha=0.5)
plt.show()

# Example SSIM improvement over epochs
ssim_epochs = [0.82, 0.85, 0.88, 0.90, 0.915, 0.9169]  # Replace with actual epoch-wise SSIM values

plt.figure(figsize=(10, 6))
plt.plot(range(1, len(ssim_epochs) + 1), ssim_epochs, marker='o', color='green', label='SSIM Score')
plt.xlabel("Epochs", fontsize=14)
plt.ylabel("SSIM Score", fontsize=14)
plt.title("SSIM Improvement Over Epochs", fontsize=16)
plt.ylim(0, 1)
plt.grid(alpha=0.5)
plt.legend(fontsize=12)
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Load the dataset
file_path = '/content/Proper_Synthetic_Dataset.csv'  # Update with your file path
synthetic_data = pd.read_csv(file_path)

# Select features and targets
features = ['Temperature', 'Manufacturing_Speed', 'Pressure', 'Humidity']
target_classification = 'Defect_Type_Label'
target_regression_1 = 'Process_Efficiency'
target_regression_2 = 'Quality_Score'

# Normalize continuous features
scaler = MinMaxScaler()
synthetic_data[features] = scaler.fit_transform(synthetic_data[features])

# Split the dataset into training, validation, and test sets
X = synthetic_data[features]
y_classification = synthetic_data[target_classification]
y_regression_1 = synthetic_data[target_regression_1]
y_regression_2 = synthetic_data[target_regression_2]

# Train-Validation-Test split (70%-15%-15%)
X_train, X_temp, y_class_train, y_class_temp, y_reg_1_train, y_reg_1_temp, y_reg_2_train, y_reg_2_temp = train_test_split(
    X, y_classification, y_regression_1, y_regression_2, test_size=0.3, random_state=42
)
X_val, X_test, y_class_val, y_class_test, y_reg_1_val, y_reg_1_test, y_reg_2_val, y_reg_2_test = train_test_split(
    X_temp, y_class_temp, y_reg_1_temp, y_reg_2_temp, test_size=0.5, random_state=42
)

# Verify the shapes of the splits
print("Training Set Shape:", X_train.shape)
print("Validation Set Shape:", X_val.shape)
print("Test Set Shape:", X_test.shape)

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout

# Define the Multi-Task Model
def create_multitask_model(input_shape):
    # Shared Input Layer
    inputs = Input(shape=input_shape)

    # Shared Dense Layers
    shared = Dense(64, activation='relu')(inputs)
    shared = Dense(128, activation='relu')(shared)
    shared = Dropout(0.3)(shared)

    # Classification Output
    classification_output = Dense(3, activation='softmax', name='classification_output')(shared)  # 3 classes

    # Regression Output 1 (Process Efficiency)
    regression_output_1 = Dense(1, activation='linear', name='regression_output_1')(shared)

    # Regression Output 2 (Quality Score)
    regression_output_2 = Dense(1, activation='linear', name='regression_output_2')(shared)

    # Model Definition
    model = Model(inputs=inputs, outputs=[classification_output, regression_output_1, regression_output_2])
    return model

# Create the model
input_shape = (X_train.shape[1],)  # 4 features
model = create_multitask_model(input_shape)

# Compile the model
model.compile(
    optimizer='adam',
    loss={
        'classification_output': 'sparse_categorical_crossentropy',
        'regression_output_1': 'mse',
        'regression_output_2': 'mse'
    },
    metrics={
        'classification_output': ['accuracy'],
        'regression_output_1': ['mae'],
        'regression_output_2': ['mae']
    }
)

# Display the model summary
model.summary()

history = model.fit(
    X_train,
    [y_class_train, y_reg_1_train, y_reg_2_train],
    validation_data=(X_val, [y_class_val, y_reg_1_val, y_reg_2_val]),
    epochs=20,
    batch_size=32,
    verbose=1
)

results = model.evaluate(
    X_test,
    [y_class_test, y_reg_1_test, y_reg_2_test],
    verbose=1
)
print("Test Results:", results)

from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam

# Define the improved multi-task model
def create_improved_multitask_model(input_shape):
    inputs = Input(shape=input_shape)

    # Shared Layers
    shared = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(inputs)
    shared = Dropout(0.4)(shared)
    shared = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(shared)
    shared = Dropout(0.4)(shared)

    # Classification Output
    classification_output = Dense(3, activation='softmax', name='classification_output')(shared)

    # Regression Output 1 (Process Efficiency)
    regression_output_1 = Dense(1, activation='linear', name='regression_output_1')(shared)

    # Regression Output 2 (Quality Score)
    regression_output_2 = Dense(1, activation='linear', name='regression_output_2')(shared)

    # Define the model
    model = Model(inputs=inputs, outputs=[classification_output, regression_output_1, regression_output_2])
    return model

# Instantiate and compile the improved model
improved_model = create_improved_multitask_model((X_train.shape[1],))
improved_model.compile(
    optimizer=Adam(learning_rate=0.0005),
    loss={
        'classification_output': 'sparse_categorical_crossentropy',
        'regression_output_1': 'mse',
        'regression_output_2': 'mse'
    },
    metrics={
        'classification_output': ['accuracy'],
        'regression_output_1': ['mae'],
        'regression_output_2': ['mae']
    }
)

# Display the model summary
improved_model.summary()

from tensorflow.keras.callbacks import EarlyStopping

# Add Early Stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the improved model
history_improved = improved_model.fit(
    X_train,
    [y_class_train, y_reg_1_train, y_reg_2_train],
    validation_data=(X_val, [y_class_val, y_reg_1_val, y_reg_2_val]),
    epochs=50,
    batch_size=16,
    callbacks=[early_stopping],
    verbose=1
)

# Evaluate on the test set
test_results = improved_model.evaluate(
    X_test,
    [y_class_test, y_reg_1_test, y_reg_2_test],
    verbose=1
)
print("Improved Model Test Results:", test_results)

import matplotlib.pyplot as plt

# Plot the loss curves
plt.figure(figsize=(10, 6))
plt.plot(history_improved.history['loss'], label='Training Loss')
plt.plot(history_improved.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(history_improved.history['classification_output_accuracy'], label='Training Accuracy')
plt.plot(history_improved.history['val_classification_output_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Classification Accuracy Over Epochs')
plt.legend()
plt.show()

import numpy as np

# Predictions
predictions = improved_model.predict(X_test)
y_class_pred, y_reg_1_pred, y_reg_2_pred = predictions

# Scatter plot for Process Efficiency
plt.figure(figsize=(8, 6))
plt.scatter(y_reg_1_test, y_reg_1_pred, alpha=0.7, label='Predicted vs Actual')
plt.plot([min(y_reg_1_test), max(y_reg_1_test)], [min(y_reg_1_test), max(y_reg_1_test)], color='red', linestyle='--', label='Ideal')
plt.xlabel('Actual Process Efficiency')
plt.ylabel('Predicted Process Efficiency')
plt.title('Regression Performance: Process Efficiency')
plt.legend()
plt.show()

# Scatter plot for Quality Score
plt.figure(figsize=(8, 6))
plt.scatter(y_reg_2_test, y_reg_2_pred, alpha=0.7, label='Predicted vs Actual')
plt.plot([min(y_reg_2_test), max(y_reg_2_test)], [min(y_reg_2_test), max(y_reg_2_test)], color='red', linestyle='--', label='Ideal')
plt.xlabel('Actual Quality Score')
plt.ylabel('Predicted Quality Score')
plt.title('Regression Performance: Quality Score')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Convert predictions to class labels
y_class_pred_labels = np.argmax(y_class_pred, axis=1)

# Generate the confusion matrix
cm = confusion_matrix(y_class_test, y_class_pred_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Defect', 'Minor Defect', 'Critical Defect'])

# Display the confusion matrix
disp.plot(cmap='Blues')
plt.title('Confusion Matrix for Defect Detection')
plt.show()

# Calculate errors
process_efficiency_error = y_reg_1_test - y_reg_1_pred.flatten()
quality_score_error = y_reg_2_test - y_reg_2_pred.flatten()

# Plot histograms
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.hist(process_efficiency_error, bins=30, alpha=0.7, label='Process Efficiency Error')
plt.axvline(x=0, color='red', linestyle='--', label='Zero Error')
plt.title('Error Distribution: Process Efficiency')
plt.xlabel('Error')
plt.ylabel('Frequency')
plt.legend()

plt.subplot(1, 2, 2)
plt.hist(quality_score_error, bins=30, alpha=0.7, label='Quality Score Error')
plt.axvline(x=0, color='red', linestyle='--', label='Zero Error')
plt.title('Error Distribution: Quality Score')
plt.xlabel('Error')
plt.ylabel('Frequency')
plt.legend()

plt.tight_layout()
plt.show()

# Residuals
process_efficiency_residuals = y_reg_1_test - y_reg_1_pred.flatten()
quality_score_residuals = y_reg_2_test - y_reg_2_pred.flatten()

# Residual plot for Process Efficiency
plt.figure(figsize=(8, 6))
plt.scatter(y_reg_1_pred.flatten(), process_efficiency_residuals, alpha=0.7, label='Residuals')
plt.axhline(y=0, color='red', linestyle='--', label='Zero Residual')
plt.xlabel('Predicted Process Efficiency')
plt.ylabel('Residuals')
plt.title('Residuals: Process Efficiency')
plt.legend()
plt.show()

# Residual plot for Quality Score
plt.figure(figsize=(8, 6))
plt.scatter(y_reg_2_pred.flatten(), quality_score_residuals, alpha=0.7, label='Residuals')
plt.axhline(y=0, color='red', linestyle='--', label='Zero Residual')
plt.xlabel('Predicted Quality Score')
plt.ylabel('Residuals')
plt.title('Residuals: Quality Score')
plt.legend()
plt.show()